{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big G Express - Machine Learning Models\n",
    "\n",
    "## Team: Elden Ring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://eldenring.wiki.fextralife.com/file/Elden-Ring/mirel_pastor_of_vow.jpg\" alt=\"PRAISE DOG\" style=\"width:806px;height:600px;\"/>\n",
    "\n",
    "#### PRAISE THE DOG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = pd.read_pickle('../data/faults_filtered.pkl')\n",
    "y_derate = pd.read_pickle('../data/target_derate.pkl') # this one is the starting/base model, 6 hr\n",
    "\n",
    "# we can load any of the other saved derate options:\n",
    "# y_derate = pd.read_pickle('../data/target_derate3h.pkl')\n",
    "# y_derate = pd.read_pickle('../data/target_derate12h.pkl')\n",
    "# y_derate = pd.read_pickle('../data/target_derate24h.pkl')\n",
    "# y_derate = pd.read_pickle('../data/target_derate1wk.pkl')\n",
    "# y_derate = pd.read_pickle('../data/target_derate6h_noderaterow.pkl')\n",
    "# y_75derate = pd.read_pickle('../data/target_75derate.pkl')\n",
    "\n",
    "diagnostics_imputed = pd.read_pickle('../data/diagnostics_imputed.pkl')\n",
    "# alternative where diagnostics were imputed using the median instead of mean\n",
    "# diagnostics_imputed = pd.read_pickle('../data/diagnostics_imputed_median.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is mostly NaNs, just 250 values or so, drop it\n",
    "diagnostics_imputed = diagnostics_imputed.drop(columns='ServiceDistance')\n",
    "\n",
    "# and this drops columns that are not useful for predictions\n",
    "faults = faults.drop(columns=['ESS_Id', 'active', 'eventDescription','ecuSoftwareVersion', 'ecuSerialNumber', \n",
    "    'ecuModel', 'ecuMake', 'ecuSource', 'MCTNumber', 'Latitude', 'Longitude', 'LocationTimeStamp'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are parts of columns (where a particular truck had no values), so those need to be filled by looking at the other trucks. I tested both a mean and value approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was just a simple fill with mean..\n",
    "diagnostics_imputed['AcceleratorPedal'] = diagnostics_imputed['AcceleratorPedal'].fillna(value=diagnostics_imputed['AcceleratorPedal'].mean())\n",
    "diagnostics_imputed['CruiseControlSetSpeed'] = diagnostics_imputed['CruiseControlSetSpeed'].fillna(value=diagnostics_imputed['CruiseControlSetSpeed'].mean())\n",
    "diagnostics_imputed['EngineTimeLtd'] = diagnostics_imputed['EngineTimeLtd'].fillna(value=diagnostics_imputed['EngineTimeLtd'].mean())\n",
    "diagnostics_imputed['FuelLevel'] = diagnostics_imputed['FuelLevel'].fillna(value=diagnostics_imputed['FuelLevel'].mean())\n",
    "diagnostics_imputed['FuelTemperature'] = diagnostics_imputed['FuelTemperature'].fillna(value=diagnostics_imputed['FuelTemperature'].mean())\n",
    "diagnostics_imputed['SwitchedBatteryVoltage'] = diagnostics_imputed['SwitchedBatteryVoltage'].fillna(value=diagnostics_imputed['SwitchedBatteryVoltage'].mean())\n",
    "diagnostics_imputed['Throttle'] = diagnostics_imputed['Throttle'].fillna(value=diagnostics_imputed['Throttle'].mean())\n",
    "\n",
    "#same but when using median - slightly worse than the mean\n",
    "# diagnostics_imputed['AcceleratorPedal'] = diagnostics_imputed['AcceleratorPedal'].fillna(value=diagnostics_imputed['AcceleratorPedal'].median())\n",
    "# diagnostics_imputed['CruiseControlSetSpeed'] = diagnostics_imputed['CruiseControlSetSpeed'].fillna(value=diagnostics_imputed['CruiseControlSetSpeed'].median())\n",
    "# diagnostics_imputed['EngineTimeLtd'] = diagnostics_imputed['EngineTimeLtd'].fillna(value=diagnostics_imputed['EngineTimeLtd'].median())\n",
    "# diagnostics_imputed['FuelLevel'] = diagnostics_imputed['FuelLevel'].fillna(value=diagnostics_imputed['FuelLevel'].median())\n",
    "# diagnostics_imputed['FuelTemperature'] = diagnostics_imputed['FuelTemperature'].fillna(value=diagnostics_imputed['FuelTemperature'].median())\n",
    "# diagnostics_imputed['SwitchedBatteryVoltage'] = diagnostics_imputed['SwitchedBatteryVoltage'].fillna(value=diagnostics_imputed['SwitchedBatteryVoltage'].median())\n",
    "# diagnostics_imputed['Throttle'] = diagnostics_imputed['Throttle'].fillna(value=diagnostics_imputed['Throttle'].median())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specially congigured Train-Test split\n",
    "\n",
    "Initially we used just a regular train-test split on the variables. However, doing that, events from same trucks whose end up mixed between both train and test split. Instead, we want to make sure that each individual truck only appears in one (either train or test, but not both).\n",
    "\n",
    "I also refined the process that I initially used and combined it into a function as below and deleted the old code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "print(faults['EquipmentID'].nunique())\n",
    "print(faults.loc[faults['spn'] == 5246]['EquipmentID'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, get the two lists of trucks that had (or not) a full derate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trucks = faults['EquipmentID'].unique()\n",
    "derate_trucks = faults.loc[faults['spn'] == 5246]['EquipmentID'].unique()\n",
    "no_derate_trucks = all_trucks[np.isin(all_trucks, derate_trucks, invert=True)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, put those lists together, marking if a derate occured (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks_df = pd.concat([\n",
    "            pd.DataFrame({'EquipmentID': derate_trucks, 'derate': 1}),\n",
    "            pd.DataFrame({'EquipmentID': no_derate_trucks, 'derate': 0}) \n",
    "            ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, use the train_test_split, by accounting for the proportion of 'derates' in both (using stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks_train, trucks_test = train_test_split(trucks_df, stratify=trucks_df['derate'], train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was used just to verify that the proportions of trucks with and without derate in two samples are equal\n",
    "# print(trucks_train['derate'].value_counts(normalize=True))\n",
    "# print(trucks_test['derate'].value_counts(normalize=True))\n",
    "\n",
    "# print(faults.loc[faults['EquipmentID'].isin(trucks_train['EquipmentID'])].shape[0])\n",
    "# print(faults.loc[faults['EquipmentID'].isin(trucks_test['EquipmentID'])].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use that information to split both the diagnostics and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the RecordID for the two splits (corresponding to the trucks)\n",
    "records_train = faults.loc[faults['EquipmentID'].isin(trucks_train['EquipmentID'])]['RecordID']\n",
    "records_test = faults.loc[faults['EquipmentID'].isin(trucks_test['EquipmentID'])]['RecordID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_derate.loc[y_derate['RecordID'].isin(records_train)].sort_values('RecordID').drop(columns='RecordID')['target']\n",
    "y_test = y_derate.loc[y_derate['RecordID'].isin(records_test)].sort_values('RecordID').drop(columns='RecordID')['target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the y_train and y_test are sorted, time to do the same for the X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics = faults.merge(diagnostics_imputed, left_on='RecordID', right_on='FaultId', how='inner').drop(columns='FaultId')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the X_train and X_test, there are different options on how we prepare them. For example, how much in the past do we aggregate for. Do we flag just which codes appeared in that time, or sum how many appeared.\n",
    "\n",
    "To be able to quickly change that and perform fits on differently prepared sets, I wrote a function below \"windowize_predictors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowize_predictors(fulldetail_faults, time_window='1d', faults_agg='max', windowize_diagnostics = True, diagnostics_agg='mean'):\n",
    "\n",
    "    # pull out the diagnostics table columns for later\n",
    "    diagnostics_cols = [col for col in fulldetail_faults.columns if col not in ['RecordID', 'spn', 'fmi', 'EquipmentID']]\n",
    "\n",
    "    # create a combined spn_fmi column to make dummies out of\n",
    "    fulldetail_faults['spn_fmi'] = ['_'.join(i) for i in zip(fulldetail_faults['spn'].astype(str), fulldetail_faults['fmi'].astype(str))]\n",
    "\n",
    "    # make dummies (one hot encode)\n",
    "    fulldetail_faults = pd.get_dummies(fulldetail_faults, columns=['spn_fmi'], prefix='spn_fmi')\n",
    "\n",
    "    # make sure the dataframe is in the right order to be able to later re-assign RecordID to it\n",
    "    fulldetail_faults = fulldetail_faults.sort_values(by=['EquipmentID', 'EventTimeStamp'])\n",
    "\n",
    "    # pull out all the Faults table columns (now one hot encoded)\n",
    "    faults_cols = ['EventTimeStamp'] + [col for col in fulldetail_faults.columns if 'spn_fmi' in col] \n",
    "\n",
    "    # rolling window function over faults - by default just taking IF a code appears in a 24 hr past window\n",
    "    faults_rolling = (\n",
    "        fulldetail_faults\n",
    "            .groupby('EquipmentID')[faults_cols]\n",
    "            .rolling(window = time_window, on = \"EventTimeStamp\")\n",
    "            .agg(faults_agg)\n",
    "            .reset_index()\n",
    "    )\n",
    "    \n",
    "    # by default I also decided to apply the same rolling window for the diagnostics part\n",
    "    # (can be turned off by setting = False, it is quick to execute)\n",
    "    if windowize_diagnostics:\n",
    "\n",
    "        # rolling window over diagnostics, by default using mean\n",
    "        diagnostics_rolling = (\n",
    "            fulldetail_faults\n",
    "                .groupby('EquipmentID')[diagnostics_cols]\n",
    "                .rolling(window = time_window, on = \"EventTimeStamp\")\n",
    "                .agg(diagnostics_agg)\n",
    "                .reset_index()\n",
    "        )\n",
    "\n",
    "        # joining back the faults rw to the original dataframe to get the \"RecordID\" out\n",
    "        faults_rolling = pd.merge(fulldetail_faults[['RecordID', 'spn']],\n",
    "                            faults_rolling,\n",
    "                            left_index= True,\n",
    "                            right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "        ###### ONLY uncomment this next line IF the derate rows are not tagged\n",
    "        # faults_rolling = faults_rolling.loc[faults_rolling['spn'] != 5246]\n",
    "\n",
    "        # joining back the diagnostics rw to the original dataframe to get the \"RecordID\" out\n",
    "        diagnostics_rolling = pd.merge(fulldetail_faults[['RecordID', 'spn']],\n",
    "                                diagnostics_rolling,\n",
    "                                left_index= True,\n",
    "                                right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "        ####### ONLY uncomment this next line IF the derate rows are not tagged\n",
    "        # diagnostics_rolling = diagnostics_rolling.loc[diagnostics_rolling['spn'] != 5246]\n",
    "        \n",
    "        # joining the two rolling windows\n",
    "        faults_diagnostics_rolling =  pd.merge(\n",
    "            diagnostics_rolling.drop(columns=['EquipmentID', 'EventTimeStamp', 'spn']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp', 'spn']),\n",
    "            on = 'RecordID'\n",
    "        )\n",
    "\n",
    "    # this gets used if we only want to take into account the current diagnostics\n",
    "    # (essentially, NO rolling window for diagnostics)\n",
    "    else :\n",
    "\n",
    "        # simply get back 'RecordID' and other diagnostic columns\n",
    "        faults_diagnostics_rolling = pd.merge(\n",
    "            fulldetail_faults[['RecordID', 'spn'] + diagnostics_cols].drop(columns=['EventTimeStamp']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            left_index= True,\n",
    "            right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "        ####### ONLY uncomment this next line IF the derate rows are not tagged\n",
    "        # faults_diagnostics_rolling = faults_diagnostics_rolling.loc[faults_diagnostics_rolling['spn'] != 5246]\n",
    "        \n",
    "        faults_diagnostics_rolling = faults_diagnostics_rolling.drop(columns='spn')\n",
    "        \n",
    "    predictor_train = (\n",
    "        faults_diagnostics_rolling\n",
    "        .loc[faults_diagnostics_rolling['RecordID']\n",
    "             .isin(records_train)]\n",
    "        .sort_values('RecordID')\n",
    "        .drop(columns='RecordID')\n",
    "    )\n",
    "    predictor_test = (\n",
    "        faults_diagnostics_rolling\n",
    "        .loc[faults_diagnostics_rolling['RecordID']\n",
    "             .isin(records_test)]\n",
    "        .sort_values('RecordID')\n",
    "        .drop(columns='RecordID')\n",
    "    )\n",
    "\n",
    "    return predictor_train, predictor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = windowize_predictors(faults_diagnostics, time_window='7d', faults_agg='max', windowize_diagnostics=True, diagnostics_agg='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True)) #, n_estimators =350, learning_rate=0.03\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I attempted to fit directly on the X_train and X_test. However, due to the class imbalance (much more lines without derate than with derate), the results were terrible - missed almost all of the derates! So I deleted the code to fit X_train and X_test directly and instead, passed on SMOTE.\n",
    "\n",
    "> NOTE: the SMOTE takes a good 25-30 min to run because there's lots of data to generate to balance the huge discrepacny between the two classes (derate vs non derate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE(k_neighbors=5, random_state=42)\n",
    "\n",
    "X_smote, y_smote = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2303           19.92m\n",
      "         2           1.1026           19.59m\n",
      "         3           0.9966           19.41m\n",
      "         4           0.9074           19.01m\n",
      "         5           0.8317           18.65m\n",
      "         6           0.7720           18.47m\n",
      "         7           0.7148           18.57m\n",
      "         8           0.6696           18.26m\n",
      "         9           0.6246           17.92m\n",
      "        10           0.5903           17.69m\n",
      "        20           0.3474           16.68m\n",
      "        30           0.2600           14.78m\n",
      "        40           0.2188           12.79m\n",
      "        50           0.1963           10.70m\n",
      "        60           0.1805            8.60m\n",
      "        70           0.1681            6.46m\n",
      "        80           0.1589            4.32m\n",
      "        90           0.1501            2.16m\n",
      "       100           0.1421            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('gb', GradientBoostingClassifier(verbose=True))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is going to re-fit from scratch, unless we set warm_start=True\n",
    "# also, simply add this line to all X_ variables if you want to exclude 5246 influencing the model:\n",
    "# .drop(columns=[col for col in X_smote.columns if 'spn_fmi_5246' in col])\n",
    "gbr.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[428651  13269]\n",
      " [    21    860]]\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    441920\n",
      "           1       0.06      0.98      0.11       881\n",
      "\n",
      "    accuracy                           0.97    442801\n",
      "   macro avg       0.53      0.97      0.55    442801\n",
      "weighted avg       1.00      0.97      0.98    442801\n",
      "\n",
      "\n",
      "\n",
      "Variable Importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LampStatus</td>\n",
       "      <td>0.397541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FuelTemperature</td>\n",
       "      <td>0.315414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>spn_fmi_1569_31</td>\n",
       "      <td>0.116364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>activeTransitionCount</td>\n",
       "      <td>0.048253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CruiseControlSetSpeed</td>\n",
       "      <td>0.020625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>spn_fmi_111_17</td>\n",
       "      <td>0.019034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>spn_fmi_3362_31</td>\n",
       "      <td>0.009580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>spn_fmi_5394_5</td>\n",
       "      <td>0.009374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>spn_fmi_1787_11</td>\n",
       "      <td>0.005330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>spn_fmi_3363_3</td>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>spn_fmi_1209_2</td>\n",
       "      <td>0.003826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>spn_fmi_596_31</td>\n",
       "      <td>0.002782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Throttle</td>\n",
       "      <td>0.002678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SwitchedBatteryVoltage</td>\n",
       "      <td>0.002656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DistanceLtd</td>\n",
       "      <td>0.002519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EngineRpm</td>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>spn_fmi_524287_31</td>\n",
       "      <td>0.002351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>spn_fmi_3251_2</td>\n",
       "      <td>0.002218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>spn_fmi_4094_18</td>\n",
       "      <td>0.002203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>spn_fmi_157_18</td>\n",
       "      <td>0.001915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   variable  importance\n",
       "15               LampStatus    0.397541\n",
       "13          FuelTemperature    0.315414\n",
       "163         spn_fmi_1569_31    0.116364\n",
       "20    activeTransitionCount    0.048253\n",
       "2     CruiseControlSetSpeed    0.020625\n",
       "90           spn_fmi_111_17    0.019034\n",
       "389         spn_fmi_3362_31    0.009580\n",
       "636          spn_fmi_5394_5    0.009374\n",
       "219         spn_fmi_1787_11    0.005330\n",
       "392          spn_fmi_3363_3    0.004143\n",
       "109          spn_fmi_1209_2    0.003826\n",
       "731          spn_fmi_596_31    0.002782\n",
       "18                 Throttle    0.002678\n",
       "17   SwitchedBatteryVoltage    0.002656\n",
       "3               DistanceLtd    0.002519\n",
       "8                 EngineRpm    0.002395\n",
       "622       spn_fmi_524287_31    0.002351\n",
       "371          spn_fmi_3251_2    0.002218\n",
       "467         spn_fmi_4094_18    0.002203\n",
       "167          spn_fmi_157_18    0.001915"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TEST\n",
      "confusion matrix\n",
      "[[100231   3439]\n",
      " [    28    175]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    103670\n",
      "           1       0.05      0.86      0.09       203\n",
      "\n",
      "    accuracy                           0.97    103873\n",
      "   macro avg       0.52      0.91      0.54    103873\n",
      "weighted avg       1.00      0.97      0.98    103873\n",
      "\n",
      "ROC AUC Score\n",
      "0.9884836595468474\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(classification_report(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "print('Variable Importances:')\n",
    "display(importances.sort_values('importance', ascending = False).head(20))\n",
    "\n",
    "print('------ TEST')\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))\n",
    "print('classification report')\n",
    "print(classification_report(y_test, gbr.predict(X_test)))\n",
    "print('ROC AUC Score')\n",
    "print(roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to try and use different configurations for the model to fit. Each time I fitted one, since it took so long to fit, I decided to save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gbr_model_28.joblib']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to load model\n",
    "# gbr = load('../models/gbr_model_1.joblib') \n",
    "\n",
    "# to save model\n",
    "#dump(gbr, '../models/gbr_model_28.joblib') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides saving the models, I also constructed a json file that describes how the models were obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dump = {\n",
    "    'file_path' : '../models/gbr_model_27.joblib',\n",
    "    'targets' : 'any row where a derate (5246) happens in the next 6 hours',\n",
    "    'diagnostics_file' : 'used imputer to average data per truck and then simple mean to average any remaining nulls',\n",
    "    'train_test_split' : 'using trucks and assuring same ratio of derate and nonderate',\n",
    "    'windowize_predictors': {'dataframe': 'merged faults and diagnostics',\n",
    "                             'how far in the past to aggregate' : '7 days',\n",
    "                             'how to aggregate the one-hot encoded spn_fmi': 'max (default)',\n",
    "                             'use rolling window on diagnostics?' : 'True ',\n",
    "                             'how to aggregate diagnostics data' : 'max'},\n",
    "    'pipeline' : {'step 1': 'GradientBoostingClassifier (default values)'},\n",
    "    'rebalancing' : {'over or under fitting': 'used SMOTE(k_neighbors=5, random_state=42)',\n",
    "                     'variables used': 'all (including derate columns)'}\n",
    "\n",
    "}\n",
    "\n",
    "tmp_matrix = confusion_matrix(y_train, gbr.predict(X_train))\n",
    "\n",
    "to_dump['train_confusion_matrix'] = {'TN': int(tmp_matrix[0][0]),\n",
    "                                     'FP': int(tmp_matrix[0][1]),\n",
    "                                     'FN': int(tmp_matrix[1][0]),\n",
    "                                     'TP': int(tmp_matrix[1][1])}\n",
    "\n",
    "tmp_matrix = confusion_matrix(y_test, gbr.predict(X_test))\n",
    "\n",
    "to_dump['test_confusion_matrix'] = {'TN': int(tmp_matrix[0][0]),\n",
    "                                    'FP': int(tmp_matrix[0][1]),\n",
    "                                    'FN': int(tmp_matrix[1][0]),\n",
    "                                    'TP': int(tmp_matrix[1][1])}\n",
    "\n",
    "\n",
    "to_dump['test_rocaouc_score'] = roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1])\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances = importances.sort_values('importance', ascending = False).head(20)\n",
    "\n",
    "tmp_dict={}\n",
    "\n",
    "for index, row in importances.iterrows():\n",
    "    tmp_dict[row[\"variable\"]] = row['importance']\n",
    "\n",
    "to_dump['top20_fature_importances'] = tmp_dict\n",
    "\n",
    "\n",
    "json_object = json.dumps(to_dump, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../models/gbr_model_28.json', 'w') as outfile:\n",
    "#     outfile.write(json_object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Which Model is ACTUALLY the best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking about it and talking to Michael I realized that there are a couple of things that are not directly evident by just looking at the confusion matrix:\n",
    "- there may be cases where derates occur after one another - those should not be counted as separate predictions (correct or otherwise)\n",
    "- we allow for about a week of truck repairs after a derate occurs\n",
    "- the future prediction window encaptures any events in that timeframe. So they could happen immediately after, or up to 6 hours later - have to eliminate any that despite being predicted correctly, we might not be able to get the truck to a shop in time\n",
    "- we do also want to give credit to the model even if a derate happens slightly later than predicted. For example, models trained to predict up to 6 hours early and a derate actually happens 8 hours later (instead of 6) - that's still a win for our predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model that I want to use to look at the predictions\n",
    "gbr_best = load('../models/gbr_model_26.joblib')\n",
    "\n",
    "# get the target values \n",
    "# note: as per comments above, always check if a derate was correctly predicted within 24 hours\n",
    "y_derate = pd.read_pickle('../data/target_derate24h.pkl')\n",
    "\n",
    "y_comparison = y_derate.loc[y_derate['RecordID'].isin(records_test)].sort_values('RecordID')\n",
    "\n",
    "# preditc y values based on model\n",
    "#.drop(columns=[col for col in X_smote.columns if 'spn_fmi_5246' in col])\n",
    "y_pred = gbr_best.predict(X_test) \n",
    "\n",
    "# put all of it together in a dataframe\n",
    "y_comparison['predicted'] = y_pred\n",
    "\n",
    "# merge it back to get the complete faults info\n",
    "test_results = pd.merge(faults, y_comparison, on='RecordID', how='inner')\n",
    "\n",
    "# flag the rows where the derate occurred\n",
    "test_results['dummy_derate'] = np.where(test_results['spn'] == 5246, 1, 0)\n",
    "\n",
    "# sort test_results in the right order since that's what's needed for rolling windows\n",
    "# note that the dummy_derate now needs to be last in case of a tie (as opposed to when we were looking in the future)\n",
    "test_results = test_results.sort_values(by=['EquipmentID','EventTimeStamp','dummy_derate'], ascending=[False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_derate = (\n",
    "    test_results\n",
    "        .groupby('EquipmentID')[['EventTimeStamp', 'dummy_derate']]\n",
    "        .rolling(window = '7d', on = \"EventTimeStamp\")\n",
    "        .sum()\n",
    "        .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.merge(test_results.drop(columns=['dummy_derate']),\n",
    "        after_derate.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "        left_index= True,\n",
    "        right_on = 'level_1').drop(columns='level_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test_results.loc[(test_results['dummy_derate'] == 0.) | (test_results['spn'] == 5246)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the confusion Matrix for the model 5:\n",
    "- \"TN\": 100535\n",
    "- \"FP\": 3099\n",
    "- \"FN\": 37\n",
    "- \"TP\": 202\n",
    "\n",
    "This is the confusion Matrix for the model 13:\n",
    "- \"TN\": 99699\n",
    "- \"FP\": 3726\n",
    "- \"FN\": 81\n",
    "- \"TP\": 367\n",
    "\n",
    "This is the confusion Matrix for the model 15:\n",
    "- \"TN\": 99585\n",
    "- \"FP\": 3840\n",
    "- \"FN\": 78\n",
    "- \"TP\": 370\n",
    "\n",
    "This is the confusion Matrix for the model 26:\n",
    "- \"TN\": 100410\n",
    "- \"FP\": 3224\n",
    "- \"FN\": 30\n",
    "- \"TP\": 209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the false positives\n",
    "false_positive = test_results.loc[(test_results['target'] == 0) & (test_results['predicted'] == 1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic here is that if I use the rolling window again, I can sum up on the \"predicted\" values. Any sums that are more than 1 indicate repeated values. I.e. they show that those predictions occur within 24 hours and therefore, they were not actually separate predictions of the model.\n",
    "\n",
    "On top of that, I realized that some \"predicted\" derates were happening AFTER a derate occured. So within the next hour or two. Those also shouldn't be counted as false predictions since the truck is likely being worked on. Talking to Michael and to my team, it was agreed that at least following a day after a derate is likely not indicative (due to truck being worked on).\n",
    "\n",
    "In order to get the unique false predictions, we count how many times 'predicted' was 1.\n",
    "\n",
    "**results**:\n",
    "- model 5: 819 out of 3099 are false positives\n",
    "- model 13: 644 out of 3726 are false positives\n",
    "- model 15: 609 out of 2840 are false positives\n",
    "- model 26: 496 out of 3224 are false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = (\n",
    "    false_positive\n",
    "    .groupby('EquipmentID')[['EventTimeStamp', 'predicted']]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>EventTimeStamp</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EquipmentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <th>653</th>\n",
       "      <td>2015-04-05 22:00:30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1366</th>\n",
       "      <th>1140</th>\n",
       "      <td>2015-06-10 01:45:22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>2015-07-01 12:38:58</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>2015-10-26 14:33:56</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>2015-10-28 15:14:30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <th>98464</th>\n",
       "      <td>2019-09-03 16:13:26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <th>98662</th>\n",
       "      <td>2019-08-25 08:30:55</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <th>100104</th>\n",
       "      <td>2019-11-25 10:19:19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">309</th>\n",
       "      <th>103417</th>\n",
       "      <td>2018-03-12 12:33:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103420</th>\n",
       "      <td>2018-03-16 05:43:56</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        EventTimeStamp  predicted\n",
       "EquipmentID                                      \n",
       "1350        653    2015-04-05 22:00:30        1.0\n",
       "1366        1140   2015-06-10 01:45:22        1.0\n",
       "            1175   2015-07-01 12:38:58        1.0\n",
       "            1302   2015-10-26 14:33:56        1.0\n",
       "            1303   2015-10-28 15:14:30        1.0\n",
       "...                                ...        ...\n",
       "2048        98464  2019-09-03 16:13:26        1.0\n",
       "2064        98662  2019-08-25 08:30:55        1.0\n",
       "2115        100104 2019-11-25 10:19:19        1.0\n",
       "309         103417 2018-03-12 12:33:31        1.0\n",
       "            103420 2018-03-16 05:43:56        1.0\n",
       "\n",
       "[496 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive.loc[false_positive['predicted'] == 1.]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar approach to get the false negatives, except now we invert target and predicted.\n",
    "\n",
    "**results**:\n",
    "- model 5: 11 out of 37 are false negatives\n",
    "- model 13: 24 out of 81 are false negatives\n",
    "- model 15: 24 out of 78 are false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the false negatives\n",
    "false_negative = test_results.loc[(test_results['target'] == 1) & (test_results['predicted'] == 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negative = (\n",
    "    false_negative\n",
    "    .groupby('EquipmentID')[['EventTimeStamp', 'target']]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "len(false_negative.loc[false_negative['target'] == 1.])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, looking at the true positives\n",
    "\n",
    "**results**: \n",
    "- 67 out of 202 are true positives, out of which 21 are predicted at least 2 hours in advance\n",
    "- 68 out of 367 are true positives, out of which 41 are predicted at least 2 hours in advance\n",
    "- 68 out of 367 are true positives, out of which 43 are predicted at least 2 hours in advance\n",
    "- 68 out of 209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the true positive\n",
    "true_positive = test_results.loc[(test_results['target'] == 1) & (test_results['predicted'] == 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = (\n",
    "    true_positive\n",
    "    .groupby('EquipmentID')[['EventTimeStamp', 'RecordID', 'predicted', 'target']]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .agg({'RecordID': lambda x: x[-1], 'predicted': 'sum', 'target': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "true_positive['RecordID'] = true_positive['RecordID'].astype(int)\n",
    "\n",
    "true_positive = true_positive.loc[true_positive['predicted'] == 1.]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: do not use iterrows to modify the dataframe it's being iterated over!! the results are not guaranteed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EquipmentID</th>\n",
       "      <th>EventTimeStamp</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>predicted</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1329</td>\n",
       "      <td>2015-02-25 13:53:08</td>\n",
       "      <td>5715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1339</td>\n",
       "      <td>2015-06-12 08:24:15</td>\n",
       "      <td>85259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1366</td>\n",
       "      <td>2015-06-11 10:08:58</td>\n",
       "      <td>84237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1366</td>\n",
       "      <td>2015-07-03 15:10:45</td>\n",
       "      <td>109732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1366</td>\n",
       "      <td>2015-09-23 07:25:22</td>\n",
       "      <td>214277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1922</td>\n",
       "      <td>2019-07-07 11:13:03</td>\n",
       "      <td>1176722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1928</td>\n",
       "      <td>2018-08-03 12:34:33</td>\n",
       "      <td>1042659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1970</td>\n",
       "      <td>2019-04-28 17:50:36</td>\n",
       "      <td>1153464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2004</td>\n",
       "      <td>2019-07-03 07:08:25</td>\n",
       "      <td>1176070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2009</td>\n",
       "      <td>2017-06-24 10:42:36</td>\n",
       "      <td>815232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    EquipmentID      EventTimeStamp  RecordID  predicted  target\n",
       "0          1329 2015-02-25 13:53:08      5715        1.0     1.0\n",
       "2          1339 2015-06-12 08:24:15     85259        1.0     1.0\n",
       "4          1366 2015-06-11 10:08:58     84237        1.0     1.0\n",
       "14         1366 2015-07-03 15:10:45    109732        1.0     1.0\n",
       "16         1366 2015-09-23 07:25:22    214277        1.0     1.0\n",
       "..          ...                 ...       ...        ...     ...\n",
       "254        1922 2019-07-07 11:13:03   1176722        1.0     1.0\n",
       "265        1928 2018-08-03 12:34:33   1042659        1.0     1.0\n",
       "266        1970 2019-04-28 17:50:36   1153464        1.0     1.0\n",
       "273        2004 2019-07-03 07:08:25   1176070        1.0     1.0\n",
       "275        2009 2017-06-24 10:42:36    815232        1.0     1.0\n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "derate_times = []\n",
    "\n",
    "# find the timestamp of next actual derate that happens\n",
    "for index, row in true_positive.iterrows():\n",
    "    derate_times.append(\n",
    "        faults.loc[(faults['EquipmentID'] == str(row['EquipmentID']))\n",
    "                   & (faults['spn'] == 5246) \n",
    "                   & (faults['EventTimeStamp'] >= row['EventTimeStamp'])]\n",
    "                   .iloc[0]['EventTimeStamp']\n",
    "    )\n",
    "\n",
    "# save that in the dataframe\n",
    "true_positive['derateTimeStamp'] = derate_times\n",
    "\n",
    "# measure how soon the prediction happened before the derate\n",
    "true_positive['timediff'] = true_positive['derateTimeStamp'] - true_positive['EventTimeStamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_positive.loc[true_positive['timediff'] > timedelta(hours= 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "496 * 500 - 4000 * 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Future Possibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of presentation, the best model I was able to come up with, predicted 496 non-derates as derates. Each wrongfully predicted derate would cost the company about $500 to get to the shop and check.\n",
    "\n",
    "On the other hand, it correctly predicted at least 2 hours in advance 42 derates (40 of them at least 3 hours in advance). That would save the company about $4000.\n",
    "\n",
    "That model was trained using a 24 hour \"future\" prediction window and a 7 day learning period (looking at which spn-fmi codes appeared during that time and observing the mean of the values in the diagnostics table).\n",
    "\n",
    "So in total: this model and data preparation, without further tweaking, would cost the company:\n",
    "4,000$ * 42 - $500 * 496 = - $80,000\n",
    "\n",
    "Given more time, I would probably attempt to use a different classifier (this was all done with GradientBoostingClassifier) - for example an XGBoost and additionally tweaking the hyperparameters. My focus was mostly on preparing the data in the \"best\" way possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Feature Importances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just an added part to explore which of the features as predicted by the model are important (it takes a while to load though, for each variable)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> WARNING: the below interact takes about a minute to load. changing variable does the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23228501ae254db1a81b203620a2afe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='feature', options=('AcceleratorPedal', 'BarometricPressure', 'Crui…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(feature = X_test.drop(columns=[col for col in X_smote.columns if 'spn_fmi_5246' in col]).columns)\n",
    "def make_pdp(feature):\n",
    "    fig, ax = plt.subplots(figsize = (10,6))\n",
    "    #ax.set_ylim([X_test['FuelTemperature'].min(), X_test['FuelTemperature'].max()])\n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        gbr, \n",
    "        X_test.drop(columns=[col for col in X_smote.columns if 'spn_fmi_5246' in col]), \n",
    "        features = [feature], #['FuelTemperature'], \n",
    "        ax = ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.8, 201.5]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X_test['FuelTemperature'].min(), X_test['FuelTemperature'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
